{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOxvc3BZGrHZ3qWCqX15gpp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hakunamatatalj/5.15test/blob/master/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgDDdkdudm9t",
        "outputId": "5009f15d-35eb-4d0d-8612-2ee7ffe73440"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'PyTorch-ENet'...\n",
            "remote: Enumerating objects: 430, done.\u001b[K\n",
            "remote: Counting objects: 100% (45/45), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
            "remote: Total 430 (delta 13), reused 28 (delta 11), pack-reused 385\u001b[K\n",
            "Receiving objects: 100% (430/430), 54.24 MiB | 17.19 MiB/s, done.\n",
            "Resolving deltas: 100% (243/243), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/davidtvs/PyTorch-ENet.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRYtytOVdrxf",
        "outputId": "d2bfe962-31b5-4ae5-865f-b1763919796a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mPyTorch-ENet\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/alexgkendall/SegNet-Tutorial.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SnilwZYdxuG",
        "outputId": "6b8db5f9-f354-464f-8469-8e63366294df"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SegNet-Tutorial'...\n",
            "remote: Enumerating objects: 2785, done.\u001b[K\n",
            "remote: Total 2785 (delta 0), reused 0 (delta 0), pack-reused 2785\u001b[K\n",
            "Receiving objects: 100% (2785/2785), 340.84 MiB | 16.92 MiB/s, done.\n",
            "Resolving deltas: 100% (81/81), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDbc8lJdd5CR",
        "outputId": "aaa1db23-7baf-4afd-f489-dc0358a57f4d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mPyTorch-ENet\u001b[0m/  \u001b[01;34msample_data\u001b[0m/  \u001b[01;34mSegNet-Tutorial\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd PyTorch-ENet/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTWXxDJ8hC-X",
        "outputId": "5bf8e637-3786-417e-9afe-af72aa71c66a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/PyTorch-ENet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXIyy-FkhDI0",
        "outputId": "16e363fa-6801-4c90-de6e-fc100469dadb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.4.2)\n",
            "Requirement already satisfied: matplotlib>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (1.21.6)\n",
            "Requirement already satisfied: Pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2018.9 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (2022.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (1.15.0)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (1.11.0+cu113)\n",
            "Requirement already satisfied: torchvision>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (0.12.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->-r requirements.txt (line 2)) (4.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.2.2->-r requirements.txt (line 11)) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.2.2->-r requirements.txt (line 11)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.2.2->-r requirements.txt (line 11)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.2.2->-r requirements.txt (line 11)) (2022.5.18.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.2.2->-r requirements.txt (line 11)) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py -m train --save-dir save/folder/ --name model_name_lj --dataset camvid --dataset-dir data/CamVid"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28wpvvIdhQY1",
        "outputId": "227b9a5d-6c1d-4a9d-9155-e19b06a9e1e0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading dataset...\n",
            "\n",
            "Selected dataset: camvid\n",
            "Dataset directory: data/CamVid\n",
            "Save directory: save/folder/\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:333: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
            "  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Number of classes to predict: 12\n",
            "Train dataset size: 367\n",
            "Validation dataset size: 101\n",
            "Image size: torch.Size([10, 3, 360, 480])\n",
            "Label size: torch.Size([10, 360, 480])\n",
            "Class-color encoding: OrderedDict([('sky', (128, 128, 128)), ('building', (128, 0, 0)), ('pole', (192, 192, 128)), ('road', (128, 64, 128)), ('pavement', (60, 40, 222)), ('tree', (128, 128, 0)), ('sign_symbol', (192, 128, 128)), ('fence', (64, 64, 128)), ('car', (64, 0, 128)), ('pedestrian', (64, 64, 0)), ('bicyclist', (0, 128, 192)), ('unlabeled', (0, 0, 0))])\n",
            "\n",
            "Weighing technique: ENet\n",
            "Computing class weights...\n",
            "(this can take a while depending on the dataset size)\n",
            "Class weights: tensor([ 5.7920,  4.4403, 34.0217,  3.4469, 15.9119,  9.0202, 32.0138, 32.4789,\n",
            "        13.2071, 38.3877, 44.1345,  0.0000], device='cuda:0')\n",
            "\n",
            "Training...\n",
            "\n",
            "ENet(\n",
            "  (initial_block): InitialBlock(\n",
            "    (main_branch): Conv2d(3, 13, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (ext_branch): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (batch_norm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (downsample1_0): DownsamplingBottleneck(\n",
            "    (main_max1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(16, 4, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.01, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (regular1_1): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.01, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (regular1_2): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.01, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (regular1_3): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.01, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (regular1_4): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.01, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (downsample2_0): DownsamplingBottleneck(\n",
            "    (main_max1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(16, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (regular2_1): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (dilated2_2): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (asymmetric2_3): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "      (3): Conv2d(32, 32, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)\n",
            "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (dilated2_4): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (regular2_5): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (dilated2_6): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (asymmetric2_7): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "      (3): Conv2d(32, 32, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)\n",
            "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (dilated2_8): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(16, 16), dilation=(16, 16), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (regular3_0): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (dilated3_1): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (asymmetric3_2): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "      (3): Conv2d(32, 32, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)\n",
            "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (dilated3_3): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (regular3_4): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (dilated3_5): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (asymmetric3_6): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(5, 1), stride=(1, 1), padding=(2, 0), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "      (3): Conv2d(32, 32, kernel_size=(1, 5), stride=(1, 1), padding=(0, 2), bias=False)\n",
            "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (dilated3_7): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(16, 16), dilation=(16, 16), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): PReLU(num_parameters=1)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): PReLU(num_parameters=1)\n",
            "  )\n",
            "  (upsample4_0): UpsamplingBottleneck(\n",
            "    (main_conv1): Sequential(\n",
            "      (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (main_unpool1): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_tconv1): ConvTranspose2d(32, 32, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
            "    (ext_tconv1_bnorm): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (ext_tconv1_activation): ReLU()\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): ReLU()\n",
            "  )\n",
            "  (regular4_1): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): ReLU()\n",
            "  )\n",
            "  (regular4_2): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): ReLU()\n",
            "  )\n",
            "  (upsample5_0): UpsamplingBottleneck(\n",
            "    (main_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (main_unpool1): MaxUnpool2d(kernel_size=(2, 2), stride=(2, 2), padding=(0, 0))\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_tconv1): ConvTranspose2d(16, 16, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
            "    (ext_tconv1_bnorm): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (ext_tconv1_activation): ReLU()\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): ReLU()\n",
            "  )\n",
            "  (regular5_1): RegularBottleneck(\n",
            "    (ext_conv1): Sequential(\n",
            "      (0): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_conv2): Sequential(\n",
            "      (0): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_conv3): Sequential(\n",
            "      (0): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (ext_regul): Dropout2d(p=0.1, inplace=False)\n",
            "    (out_activation): ReLU()\n",
            "  )\n",
            "  (transposed_conv): ConvTranspose2d(16, 12, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            ")\n",
            "\n",
            ">>>> [Epoch: 0] Training\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:749: UserWarning: Note that order of the arguments: ceil_mode and return_indices will changeto match the args list in nn.MaxPool2d in a future release.\n",
            "  warnings.warn(\"Note that order of the arguments: ceil_mode and return_indices will change\"\n",
            ">>>> [Epoch: 0] Avg. loss: 2.3309 | Mean IoU: 0.0790\n",
            ">>>> [Epoch: 1] Training\n",
            ">>>> [Epoch: 1] Avg. loss: 1.9926 | Mean IoU: 0.1646\n",
            ">>>> [Epoch: 2] Training\n",
            ">>>> [Epoch: 2] Avg. loss: 1.7322 | Mean IoU: 0.2065\n",
            ">>>> [Epoch: 3] Training\n",
            ">>>> [Epoch: 3] Avg. loss: 1.5566 | Mean IoU: 0.2302\n",
            ">>>> [Epoch: 4] Training\n",
            ">>>> [Epoch: 4] Avg. loss: 1.4386 | Mean IoU: 0.2627\n",
            ">>>> [Epoch: 5] Training\n",
            ">>>> [Epoch: 5] Avg. loss: 1.3359 | Mean IoU: 0.2853\n",
            ">>>> [Epoch: 6] Training\n",
            ">>>> [Epoch: 6] Avg. loss: 1.2594 | Mean IoU: 0.3108\n",
            ">>>> [Epoch: 7] Training\n",
            ">>>> [Epoch: 7] Avg. loss: 1.1921 | Mean IoU: 0.3165\n",
            ">>>> [Epoch: 8] Training\n",
            ">>>> [Epoch: 8] Avg. loss: 1.1329 | Mean IoU: 0.3266\n",
            ">>>> [Epoch: 9] Training\n",
            ">>>> [Epoch: 9] Avg. loss: 1.0885 | Mean IoU: 0.3335\n",
            ">>>> [Epoch: 9] Validation\n",
            ">>>> [Epoch: 9] Avg. loss: 1.3137 | Mean IoU: 0.3028\n",
            "sky: 0.9279\n",
            "building: 0.6414\n",
            "pole: 0.0000\n",
            "road: 0.7503\n",
            "pavement: 0.0671\n",
            "tree: 0.7955\n",
            "sign_symbol: 0.0003\n",
            "fence: 0.0025\n",
            "car: 0.1456\n",
            "pedestrian: 0.0000\n",
            "bicyclist: 0.0000\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 10] Training\n",
            ">>>> [Epoch: 10] Avg. loss: 1.0450 | Mean IoU: 0.3462\n",
            ">>>> [Epoch: 11] Training\n",
            ">>>> [Epoch: 11] Avg. loss: 0.9872 | Mean IoU: 0.3696\n",
            ">>>> [Epoch: 12] Training\n",
            ">>>> [Epoch: 12] Avg. loss: 0.9535 | Mean IoU: 0.3882\n",
            ">>>> [Epoch: 13] Training\n",
            ">>>> [Epoch: 13] Avg. loss: 0.8995 | Mean IoU: 0.4076\n",
            ">>>> [Epoch: 14] Training\n",
            ">>>> [Epoch: 14] Avg. loss: 0.8711 | Mean IoU: 0.4124\n",
            ">>>> [Epoch: 15] Training\n",
            ">>>> [Epoch: 15] Avg. loss: 0.8587 | Mean IoU: 0.4203\n",
            ">>>> [Epoch: 16] Training\n",
            ">>>> [Epoch: 16] Avg. loss: 0.8144 | Mean IoU: 0.4279\n",
            ">>>> [Epoch: 17] Training\n",
            ">>>> [Epoch: 17] Avg. loss: 0.7828 | Mean IoU: 0.4401\n",
            ">>>> [Epoch: 18] Training\n",
            ">>>> [Epoch: 18] Avg. loss: 0.7654 | Mean IoU: 0.4483\n",
            ">>>> [Epoch: 19] Training\n",
            ">>>> [Epoch: 19] Avg. loss: 0.7395 | Mean IoU: 0.4570\n",
            ">>>> [Epoch: 19] Validation\n",
            ">>>> [Epoch: 19] Avg. loss: 0.8397 | Mean IoU: 0.4821\n",
            "sky: 0.9341\n",
            "building: 0.7434\n",
            "pole: 0.0041\n",
            "road: 0.9362\n",
            "pavement: 0.7096\n",
            "tree: 0.8915\n",
            "sign_symbol: 0.1278\n",
            "fence: 0.3063\n",
            "car: 0.6172\n",
            "pedestrian: 0.0326\n",
            "bicyclist: 0.0001\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 20] Training\n",
            ">>>> [Epoch: 20] Avg. loss: 0.7234 | Mean IoU: 0.4587\n",
            ">>>> [Epoch: 21] Training\n",
            ">>>> [Epoch: 21] Avg. loss: 0.7079 | Mean IoU: 0.4634\n",
            ">>>> [Epoch: 22] Training\n",
            ">>>> [Epoch: 22] Avg. loss: 0.6838 | Mean IoU: 0.4708\n",
            ">>>> [Epoch: 23] Training\n",
            ">>>> [Epoch: 23] Avg. loss: 0.6650 | Mean IoU: 0.4788\n",
            ">>>> [Epoch: 24] Training\n",
            ">>>> [Epoch: 24] Avg. loss: 0.6393 | Mean IoU: 0.4889\n",
            ">>>> [Epoch: 25] Training\n",
            ">>>> [Epoch: 25] Avg. loss: 0.6432 | Mean IoU: 0.4887\n",
            ">>>> [Epoch: 26] Training\n",
            ">>>> [Epoch: 26] Avg. loss: 0.6149 | Mean IoU: 0.5066\n",
            ">>>> [Epoch: 27] Training\n",
            ">>>> [Epoch: 27] Avg. loss: 0.6111 | Mean IoU: 0.5051\n",
            ">>>> [Epoch: 28] Training\n",
            ">>>> [Epoch: 28] Avg. loss: 0.5871 | Mean IoU: 0.5196\n",
            ">>>> [Epoch: 29] Training\n",
            ">>>> [Epoch: 29] Avg. loss: 0.5791 | Mean IoU: 0.5280\n",
            ">>>> [Epoch: 29] Validation\n",
            ">>>> [Epoch: 29] Avg. loss: 0.6874 | Mean IoU: 0.5146\n",
            "sky: 0.9248\n",
            "building: 0.7244\n",
            "pole: 0.0135\n",
            "road: 0.9487\n",
            "pavement: 0.7657\n",
            "tree: 0.8723\n",
            "sign_symbol: 0.2448\n",
            "fence: 0.5703\n",
            "car: 0.4736\n",
            "pedestrian: 0.1159\n",
            "bicyclist: 0.0070\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 30] Training\n",
            ">>>> [Epoch: 30] Avg. loss: 0.5663 | Mean IoU: 0.5374\n",
            ">>>> [Epoch: 31] Training\n",
            ">>>> [Epoch: 31] Avg. loss: 0.5593 | Mean IoU: 0.5400\n",
            ">>>> [Epoch: 32] Training\n",
            ">>>> [Epoch: 32] Avg. loss: 0.5277 | Mean IoU: 0.5554\n",
            ">>>> [Epoch: 33] Training\n",
            ">>>> [Epoch: 33] Avg. loss: 0.5115 | Mean IoU: 0.5614\n",
            ">>>> [Epoch: 34] Training\n",
            ">>>> [Epoch: 34] Avg. loss: 0.4991 | Mean IoU: 0.5688\n",
            ">>>> [Epoch: 35] Training\n",
            ">>>> [Epoch: 35] Avg. loss: 0.5030 | Mean IoU: 0.5682\n",
            ">>>> [Epoch: 36] Training\n",
            ">>>> [Epoch: 36] Avg. loss: 0.4750 | Mean IoU: 0.5815\n",
            ">>>> [Epoch: 37] Training\n",
            ">>>> [Epoch: 37] Avg. loss: 0.4694 | Mean IoU: 0.5864\n",
            ">>>> [Epoch: 38] Training\n",
            ">>>> [Epoch: 38] Avg. loss: 0.4471 | Mean IoU: 0.5952\n",
            ">>>> [Epoch: 39] Training\n",
            ">>>> [Epoch: 39] Avg. loss: 0.4411 | Mean IoU: 0.6050\n",
            ">>>> [Epoch: 39] Validation\n",
            ">>>> [Epoch: 39] Avg. loss: 0.5388 | Mean IoU: 0.5683\n",
            "sky: 0.9326\n",
            "building: 0.7409\n",
            "pole: 0.0371\n",
            "road: 0.9512\n",
            "pavement: 0.7872\n",
            "tree: 0.8855\n",
            "sign_symbol: 0.3070\n",
            "fence: 0.6414\n",
            "car: 0.6540\n",
            "pedestrian: 0.1133\n",
            "bicyclist: 0.2013\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 40] Training\n",
            ">>>> [Epoch: 40] Avg. loss: 0.4420 | Mean IoU: 0.6032\n",
            ">>>> [Epoch: 41] Training\n",
            ">>>> [Epoch: 41] Avg. loss: 0.4291 | Mean IoU: 0.6099\n",
            ">>>> [Epoch: 42] Training\n",
            ">>>> [Epoch: 42] Avg. loss: 0.4230 | Mean IoU: 0.6179\n",
            ">>>> [Epoch: 43] Training\n",
            ">>>> [Epoch: 43] Avg. loss: 0.4212 | Mean IoU: 0.6187\n",
            ">>>> [Epoch: 44] Training\n",
            ">>>> [Epoch: 44] Avg. loss: 0.4069 | Mean IoU: 0.6265\n",
            ">>>> [Epoch: 45] Training\n",
            ">>>> [Epoch: 45] Avg. loss: 0.3957 | Mean IoU: 0.6322\n",
            ">>>> [Epoch: 46] Training\n",
            ">>>> [Epoch: 46] Avg. loss: 0.3940 | Mean IoU: 0.6420\n",
            ">>>> [Epoch: 47] Training\n",
            ">>>> [Epoch: 47] Avg. loss: 0.3798 | Mean IoU: 0.6470\n",
            ">>>> [Epoch: 48] Training\n",
            ">>>> [Epoch: 48] Avg. loss: 0.3665 | Mean IoU: 0.6545\n",
            ">>>> [Epoch: 49] Training\n",
            ">>>> [Epoch: 49] Avg. loss: 0.3649 | Mean IoU: 0.6610\n",
            ">>>> [Epoch: 49] Validation\n",
            ">>>> [Epoch: 49] Avg. loss: 0.5035 | Mean IoU: 0.6023\n",
            "sky: 0.9299\n",
            "building: 0.7747\n",
            "pole: 0.0463\n",
            "road: 0.9489\n",
            "pavement: 0.7961\n",
            "tree: 0.8729\n",
            "sign_symbol: 0.2751\n",
            "fence: 0.6402\n",
            "car: 0.6744\n",
            "pedestrian: 0.1807\n",
            "bicyclist: 0.4859\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 50] Training\n",
            ">>>> [Epoch: 50] Avg. loss: 0.3661 | Mean IoU: 0.6581\n",
            ">>>> [Epoch: 51] Training\n",
            ">>>> [Epoch: 51] Avg. loss: 0.3517 | Mean IoU: 0.6700\n",
            ">>>> [Epoch: 52] Training\n",
            ">>>> [Epoch: 52] Avg. loss: 0.3501 | Mean IoU: 0.6727\n",
            ">>>> [Epoch: 53] Training\n",
            ">>>> [Epoch: 53] Avg. loss: 0.3463 | Mean IoU: 0.6751\n",
            ">>>> [Epoch: 54] Training\n",
            ">>>> [Epoch: 54] Avg. loss: 0.3399 | Mean IoU: 0.6783\n",
            ">>>> [Epoch: 55] Training\n",
            ">>>> [Epoch: 55] Avg. loss: 0.3350 | Mean IoU: 0.6817\n",
            ">>>> [Epoch: 56] Training\n",
            ">>>> [Epoch: 56] Avg. loss: 0.3322 | Mean IoU: 0.6830\n",
            ">>>> [Epoch: 57] Training\n",
            ">>>> [Epoch: 57] Avg. loss: 0.3325 | Mean IoU: 0.6826\n",
            ">>>> [Epoch: 58] Training\n",
            ">>>> [Epoch: 58] Avg. loss: 0.3273 | Mean IoU: 0.6850\n",
            ">>>> [Epoch: 59] Training\n",
            ">>>> [Epoch: 59] Avg. loss: 0.3236 | Mean IoU: 0.6871\n",
            ">>>> [Epoch: 59] Validation\n",
            ">>>> [Epoch: 59] Avg. loss: 0.4694 | Mean IoU: 0.6034\n",
            "sky: 0.9364\n",
            "building: 0.7042\n",
            "pole: 0.0620\n",
            "road: 0.9569\n",
            "pavement: 0.8003\n",
            "tree: 0.8820\n",
            "sign_symbol: 0.2534\n",
            "fence: 0.6301\n",
            "car: 0.6408\n",
            "pedestrian: 0.1533\n",
            "bicyclist: 0.6180\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 60] Training\n",
            ">>>> [Epoch: 60] Avg. loss: 0.3112 | Mean IoU: 0.6993\n",
            ">>>> [Epoch: 61] Training\n",
            ">>>> [Epoch: 61] Avg. loss: 0.3069 | Mean IoU: 0.7030\n",
            ">>>> [Epoch: 62] Training\n",
            ">>>> [Epoch: 62] Avg. loss: 0.3068 | Mean IoU: 0.7003\n",
            ">>>> [Epoch: 63] Training\n",
            ">>>> [Epoch: 63] Avg. loss: 0.2946 | Mean IoU: 0.7071\n",
            ">>>> [Epoch: 64] Training\n",
            ">>>> [Epoch: 64] Avg. loss: 0.2958 | Mean IoU: 0.7103\n",
            ">>>> [Epoch: 65] Training\n",
            ">>>> [Epoch: 65] Avg. loss: 0.3010 | Mean IoU: 0.7024\n",
            ">>>> [Epoch: 66] Training\n",
            ">>>> [Epoch: 66] Avg. loss: 0.2859 | Mean IoU: 0.7149\n",
            ">>>> [Epoch: 67] Training\n",
            ">>>> [Epoch: 67] Avg. loss: 0.2872 | Mean IoU: 0.7156\n",
            ">>>> [Epoch: 68] Training\n",
            ">>>> [Epoch: 68] Avg. loss: 0.2819 | Mean IoU: 0.7177\n",
            ">>>> [Epoch: 69] Training\n",
            ">>>> [Epoch: 69] Avg. loss: 0.2730 | Mean IoU: 0.7223\n",
            ">>>> [Epoch: 69] Validation\n",
            ">>>> [Epoch: 69] Avg. loss: 0.4853 | Mean IoU: 0.6299\n",
            "sky: 0.9365\n",
            "building: 0.7976\n",
            "pole: 0.0273\n",
            "road: 0.9587\n",
            "pavement: 0.8303\n",
            "tree: 0.8927\n",
            "sign_symbol: 0.2770\n",
            "fence: 0.6664\n",
            "car: 0.7206\n",
            "pedestrian: 0.1989\n",
            "bicyclist: 0.6230\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 70] Training\n",
            ">>>> [Epoch: 70] Avg. loss: 0.2841 | Mean IoU: 0.7102\n",
            ">>>> [Epoch: 71] Training\n",
            ">>>> [Epoch: 71] Avg. loss: 0.2840 | Mean IoU: 0.7161\n",
            ">>>> [Epoch: 72] Training\n",
            ">>>> [Epoch: 72] Avg. loss: 0.2757 | Mean IoU: 0.7176\n",
            ">>>> [Epoch: 73] Training\n",
            ">>>> [Epoch: 73] Avg. loss: 0.2649 | Mean IoU: 0.7285\n",
            ">>>> [Epoch: 74] Training\n",
            ">>>> [Epoch: 74] Avg. loss: 0.2625 | Mean IoU: 0.7291\n",
            ">>>> [Epoch: 75] Training\n",
            ">>>> [Epoch: 75] Avg. loss: 0.2628 | Mean IoU: 0.7310\n",
            ">>>> [Epoch: 76] Training\n",
            ">>>> [Epoch: 76] Avg. loss: 0.2600 | Mean IoU: 0.7297\n",
            ">>>> [Epoch: 77] Training\n",
            ">>>> [Epoch: 77] Avg. loss: 0.2534 | Mean IoU: 0.7359\n",
            ">>>> [Epoch: 78] Training\n",
            ">>>> [Epoch: 78] Avg. loss: 0.2562 | Mean IoU: 0.7346\n",
            ">>>> [Epoch: 79] Training\n",
            ">>>> [Epoch: 79] Avg. loss: 0.2523 | Mean IoU: 0.7363\n",
            ">>>> [Epoch: 79] Validation\n",
            ">>>> [Epoch: 79] Avg. loss: 0.4611 | Mean IoU: 0.6356\n",
            "sky: 0.9379\n",
            "building: 0.8041\n",
            "pole: 0.0523\n",
            "road: 0.9591\n",
            "pavement: 0.8406\n",
            "tree: 0.8931\n",
            "sign_symbol: 0.2697\n",
            "fence: 0.6555\n",
            "car: 0.6295\n",
            "pedestrian: 0.2852\n",
            "bicyclist: 0.6651\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 80] Training\n",
            ">>>> [Epoch: 80] Avg. loss: 0.2527 | Mean IoU: 0.7352\n",
            ">>>> [Epoch: 81] Training\n",
            ">>>> [Epoch: 81] Avg. loss: 0.2414 | Mean IoU: 0.7427\n",
            ">>>> [Epoch: 82] Training\n",
            ">>>> [Epoch: 82] Avg. loss: 0.2423 | Mean IoU: 0.7407\n",
            ">>>> [Epoch: 83] Training\n",
            ">>>> [Epoch: 83] Avg. loss: 0.2486 | Mean IoU: 0.7343\n",
            ">>>> [Epoch: 84] Training\n",
            ">>>> [Epoch: 84] Avg. loss: 0.2711 | Mean IoU: 0.7204\n",
            ">>>> [Epoch: 85] Training\n",
            ">>>> [Epoch: 85] Avg. loss: 0.2422 | Mean IoU: 0.7407\n",
            ">>>> [Epoch: 86] Training\n",
            ">>>> [Epoch: 86] Avg. loss: 0.2339 | Mean IoU: 0.7480\n",
            ">>>> [Epoch: 87] Training\n",
            ">>>> [Epoch: 87] Avg. loss: 0.2298 | Mean IoU: 0.7502\n",
            ">>>> [Epoch: 88] Training\n",
            ">>>> [Epoch: 88] Avg. loss: 0.2265 | Mean IoU: 0.7529\n",
            ">>>> [Epoch: 89] Training\n",
            ">>>> [Epoch: 89] Avg. loss: 0.2388 | Mean IoU: 0.7455\n",
            ">>>> [Epoch: 89] Validation\n",
            ">>>> [Epoch: 89] Avg. loss: 0.5325 | Mean IoU: 0.6304\n",
            ">>>> [Epoch: 90] Training\n",
            ">>>> [Epoch: 90] Avg. loss: 0.2280 | Mean IoU: 0.7503\n",
            ">>>> [Epoch: 91] Training\n",
            ">>>> [Epoch: 91] Avg. loss: 0.2278 | Mean IoU: 0.7484\n",
            ">>>> [Epoch: 92] Training\n",
            ">>>> [Epoch: 92] Avg. loss: 0.2227 | Mean IoU: 0.7557\n",
            ">>>> [Epoch: 93] Training\n",
            ">>>> [Epoch: 93] Avg. loss: 0.2268 | Mean IoU: 0.7524\n",
            ">>>> [Epoch: 94] Training\n",
            ">>>> [Epoch: 94] Avg. loss: 0.2236 | Mean IoU: 0.7542\n",
            ">>>> [Epoch: 95] Training\n",
            ">>>> [Epoch: 95] Avg. loss: 0.2209 | Mean IoU: 0.7552\n",
            ">>>> [Epoch: 96] Training\n",
            ">>>> [Epoch: 96] Avg. loss: 0.2202 | Mean IoU: 0.7569\n",
            ">>>> [Epoch: 97] Training\n",
            ">>>> [Epoch: 97] Avg. loss: 0.2234 | Mean IoU: 0.7551\n",
            ">>>> [Epoch: 98] Training\n",
            ">>>> [Epoch: 98] Avg. loss: 0.2298 | Mean IoU: 0.7454\n",
            ">>>> [Epoch: 99] Training\n",
            ">>>> [Epoch: 99] Avg. loss: 0.2265 | Mean IoU: 0.7508\n",
            ">>>> [Epoch: 99] Validation\n",
            ">>>> [Epoch: 99] Avg. loss: 0.4945 | Mean IoU: 0.6413\n",
            "sky: 0.9348\n",
            "building: 0.8258\n",
            "pole: 0.0453\n",
            "road: 0.9644\n",
            "pavement: 0.8298\n",
            "tree: 0.8905\n",
            "sign_symbol: 0.2871\n",
            "fence: 0.6608\n",
            "car: 0.6114\n",
            "pedestrian: 0.3392\n",
            "bicyclist: 0.6647\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 100] Training\n",
            ">>>> [Epoch: 100] Avg. loss: 0.2062 | Mean IoU: 0.7686\n",
            ">>>> [Epoch: 101] Training\n",
            ">>>> [Epoch: 101] Avg. loss: 0.2004 | Mean IoU: 0.7720\n",
            ">>>> [Epoch: 102] Training\n",
            ">>>> [Epoch: 102] Avg. loss: 0.1981 | Mean IoU: 0.7738\n",
            ">>>> [Epoch: 103] Training\n",
            ">>>> [Epoch: 103] Avg. loss: 0.1973 | Mean IoU: 0.7752\n",
            ">>>> [Epoch: 104] Training\n",
            ">>>> [Epoch: 104] Avg. loss: 0.1949 | Mean IoU: 0.7785\n",
            ">>>> [Epoch: 105] Training\n",
            ">>>> [Epoch: 105] Avg. loss: 0.1933 | Mean IoU: 0.7786\n",
            ">>>> [Epoch: 106] Training\n",
            ">>>> [Epoch: 106] Avg. loss: 0.1969 | Mean IoU: 0.7765\n",
            ">>>> [Epoch: 107] Training\n",
            ">>>> [Epoch: 107] Avg. loss: 0.1943 | Mean IoU: 0.7750\n",
            ">>>> [Epoch: 108] Training\n",
            ">>>> [Epoch: 108] Avg. loss: 0.1939 | Mean IoU: 0.7783\n",
            ">>>> [Epoch: 109] Training\n",
            ">>>> [Epoch: 109] Avg. loss: 0.1939 | Mean IoU: 0.7787\n",
            ">>>> [Epoch: 109] Validation\n",
            ">>>> [Epoch: 109] Avg. loss: 0.4998 | Mean IoU: 0.6524\n",
            "sky: 0.9356\n",
            "building: 0.8371\n",
            "pole: 0.0514\n",
            "road: 0.9640\n",
            "pavement: 0.8448\n",
            "tree: 0.8921\n",
            "sign_symbol: 0.3094\n",
            "fence: 0.6654\n",
            "car: 0.6919\n",
            "pedestrian: 0.3300\n",
            "bicyclist: 0.6552\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 110] Training\n",
            ">>>> [Epoch: 110] Avg. loss: 0.1897 | Mean IoU: 0.7807\n",
            ">>>> [Epoch: 111] Training\n",
            ">>>> [Epoch: 111] Avg. loss: 0.1939 | Mean IoU: 0.7794\n",
            ">>>> [Epoch: 112] Training\n",
            ">>>> [Epoch: 112] Avg. loss: 0.1904 | Mean IoU: 0.7830\n",
            ">>>> [Epoch: 113] Training\n",
            ">>>> [Epoch: 113] Avg. loss: 0.1916 | Mean IoU: 0.7797\n",
            ">>>> [Epoch: 114] Training\n",
            ">>>> [Epoch: 114] Avg. loss: 0.1900 | Mean IoU: 0.7834\n",
            ">>>> [Epoch: 115] Training\n",
            ">>>> [Epoch: 115] Avg. loss: 0.1910 | Mean IoU: 0.7779\n",
            ">>>> [Epoch: 116] Training\n",
            ">>>> [Epoch: 116] Avg. loss: 0.1899 | Mean IoU: 0.7848\n",
            ">>>> [Epoch: 117] Training\n",
            ">>>> [Epoch: 117] Avg. loss: 0.1892 | Mean IoU: 0.7818\n",
            ">>>> [Epoch: 118] Training\n",
            ">>>> [Epoch: 118] Avg. loss: 0.1867 | Mean IoU: 0.7838\n",
            ">>>> [Epoch: 119] Training\n",
            ">>>> [Epoch: 119] Avg. loss: 0.1840 | Mean IoU: 0.7861\n",
            ">>>> [Epoch: 119] Validation\n",
            ">>>> [Epoch: 119] Avg. loss: 0.5248 | Mean IoU: 0.6539\n",
            "sky: 0.9359\n",
            "building: 0.8460\n",
            "pole: 0.0525\n",
            "road: 0.9641\n",
            "pavement: 0.8488\n",
            "tree: 0.8915\n",
            "sign_symbol: 0.3179\n",
            "fence: 0.6683\n",
            "car: 0.6894\n",
            "pedestrian: 0.3323\n",
            "bicyclist: 0.6461\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 120] Training\n",
            ">>>> [Epoch: 120] Avg. loss: 0.1862 | Mean IoU: 0.7838\n",
            ">>>> [Epoch: 121] Training\n",
            ">>>> [Epoch: 121] Avg. loss: 0.1845 | Mean IoU: 0.7845\n",
            ">>>> [Epoch: 122] Training\n",
            ">>>> [Epoch: 122] Avg. loss: 0.1846 | Mean IoU: 0.7851\n",
            ">>>> [Epoch: 123] Training\n",
            ">>>> [Epoch: 123] Avg. loss: 0.1881 | Mean IoU: 0.7839\n",
            ">>>> [Epoch: 124] Training\n",
            ">>>> [Epoch: 124] Avg. loss: 0.1867 | Mean IoU: 0.7831\n",
            ">>>> [Epoch: 125] Training\n",
            ">>>> [Epoch: 125] Avg. loss: 0.1834 | Mean IoU: 0.7860\n",
            ">>>> [Epoch: 126] Training\n",
            ">>>> [Epoch: 126] Avg. loss: 0.1821 | Mean IoU: 0.7873\n",
            ">>>> [Epoch: 127] Training\n",
            ">>>> [Epoch: 127] Avg. loss: 0.1851 | Mean IoU: 0.7861\n",
            ">>>> [Epoch: 128] Training\n",
            ">>>> [Epoch: 128] Avg. loss: 0.1834 | Mean IoU: 0.7855\n",
            ">>>> [Epoch: 129] Training\n",
            ">>>> [Epoch: 129] Avg. loss: 0.1844 | Mean IoU: 0.7860\n",
            ">>>> [Epoch: 129] Validation\n",
            ">>>> [Epoch: 129] Avg. loss: 0.5403 | Mean IoU: 0.6520\n",
            ">>>> [Epoch: 130] Training\n",
            ">>>> [Epoch: 130] Avg. loss: 0.1812 | Mean IoU: 0.7864\n",
            ">>>> [Epoch: 131] Training\n",
            ">>>> [Epoch: 131] Avg. loss: 0.1857 | Mean IoU: 0.7861\n",
            ">>>> [Epoch: 132] Training\n",
            ">>>> [Epoch: 132] Avg. loss: 0.1850 | Mean IoU: 0.7835\n",
            ">>>> [Epoch: 133] Training\n",
            ">>>> [Epoch: 133] Avg. loss: 0.1838 | Mean IoU: 0.7872\n",
            ">>>> [Epoch: 134] Training\n",
            ">>>> [Epoch: 134] Avg. loss: 0.1804 | Mean IoU: 0.7887\n",
            ">>>> [Epoch: 135] Training\n",
            ">>>> [Epoch: 135] Avg. loss: 0.1827 | Mean IoU: 0.7861\n",
            ">>>> [Epoch: 136] Training\n",
            ">>>> [Epoch: 136] Avg. loss: 0.1844 | Mean IoU: 0.7855\n",
            ">>>> [Epoch: 137] Training\n",
            ">>>> [Epoch: 137] Avg. loss: 0.1819 | Mean IoU: 0.7881\n",
            ">>>> [Epoch: 138] Training\n",
            ">>>> [Epoch: 138] Avg. loss: 0.1792 | Mean IoU: 0.7899\n",
            ">>>> [Epoch: 139] Training\n",
            ">>>> [Epoch: 139] Avg. loss: 0.1778 | Mean IoU: 0.7889\n",
            ">>>> [Epoch: 139] Validation\n",
            ">>>> [Epoch: 139] Avg. loss: 0.5280 | Mean IoU: 0.6541\n",
            "sky: 0.9374\n",
            "building: 0.8445\n",
            "pole: 0.0493\n",
            "road: 0.9663\n",
            "pavement: 0.8511\n",
            "tree: 0.8930\n",
            "sign_symbol: 0.3070\n",
            "fence: 0.6720\n",
            "car: 0.6893\n",
            "pedestrian: 0.3343\n",
            "bicyclist: 0.6508\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 140] Training\n",
            ">>>> [Epoch: 140] Avg. loss: 0.1804 | Mean IoU: 0.7896\n",
            ">>>> [Epoch: 141] Training\n",
            ">>>> [Epoch: 141] Avg. loss: 0.1800 | Mean IoU: 0.7867\n",
            ">>>> [Epoch: 142] Training\n",
            ">>>> [Epoch: 142] Avg. loss: 0.1830 | Mean IoU: 0.7879\n",
            ">>>> [Epoch: 143] Training\n",
            ">>>> [Epoch: 143] Avg. loss: 0.1820 | Mean IoU: 0.7881\n",
            ">>>> [Epoch: 144] Training\n",
            ">>>> [Epoch: 144] Avg. loss: 0.1802 | Mean IoU: 0.7879\n",
            ">>>> [Epoch: 145] Training\n",
            ">>>> [Epoch: 145] Avg. loss: 0.1815 | Mean IoU: 0.7901\n",
            ">>>> [Epoch: 146] Training\n",
            ">>>> [Epoch: 146] Avg. loss: 0.1829 | Mean IoU: 0.7858\n",
            ">>>> [Epoch: 147] Training\n",
            ">>>> [Epoch: 147] Avg. loss: 0.1812 | Mean IoU: 0.7871\n",
            ">>>> [Epoch: 148] Training\n",
            ">>>> [Epoch: 148] Avg. loss: 0.1782 | Mean IoU: 0.7907\n",
            ">>>> [Epoch: 149] Training\n",
            ">>>> [Epoch: 149] Avg. loss: 0.1784 | Mean IoU: 0.7901\n",
            ">>>> [Epoch: 149] Validation\n",
            ">>>> [Epoch: 149] Avg. loss: 0.5366 | Mean IoU: 0.6568\n",
            "sky: 0.9382\n",
            "building: 0.8490\n",
            "pole: 0.0516\n",
            "road: 0.9650\n",
            "pavement: 0.8542\n",
            "tree: 0.8933\n",
            "sign_symbol: 0.3141\n",
            "fence: 0.6691\n",
            "car: 0.7276\n",
            "pedestrian: 0.3182\n",
            "bicyclist: 0.6447\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 150] Training\n",
            ">>>> [Epoch: 150] Avg. loss: 0.1780 | Mean IoU: 0.7910\n",
            ">>>> [Epoch: 151] Training\n",
            ">>>> [Epoch: 151] Avg. loss: 0.1792 | Mean IoU: 0.7893\n",
            ">>>> [Epoch: 152] Training\n",
            ">>>> [Epoch: 152] Avg. loss: 0.1803 | Mean IoU: 0.7903\n",
            ">>>> [Epoch: 153] Training\n",
            ">>>> [Epoch: 153] Avg. loss: 0.1794 | Mean IoU: 0.7878\n",
            ">>>> [Epoch: 154] Training\n",
            ">>>> [Epoch: 154] Avg. loss: 0.1768 | Mean IoU: 0.7898\n",
            ">>>> [Epoch: 155] Training\n",
            ">>>> [Epoch: 155] Avg. loss: 0.1775 | Mean IoU: 0.7929\n",
            ">>>> [Epoch: 156] Training\n",
            ">>>> [Epoch: 156] Avg. loss: 0.1781 | Mean IoU: 0.7905\n",
            ">>>> [Epoch: 157] Training\n",
            ">>>> [Epoch: 157] Avg. loss: 0.1795 | Mean IoU: 0.7892\n",
            ">>>> [Epoch: 158] Training\n",
            ">>>> [Epoch: 158] Avg. loss: 0.1762 | Mean IoU: 0.7906\n",
            ">>>> [Epoch: 159] Training\n",
            ">>>> [Epoch: 159] Avg. loss: 0.1741 | Mean IoU: 0.7932\n",
            ">>>> [Epoch: 159] Validation\n",
            ">>>> [Epoch: 159] Avg. loss: 0.5551 | Mean IoU: 0.6533\n",
            ">>>> [Epoch: 160] Training\n",
            ">>>> [Epoch: 160] Avg. loss: 0.1769 | Mean IoU: 0.7910\n",
            ">>>> [Epoch: 161] Training\n",
            ">>>> [Epoch: 161] Avg. loss: 0.1731 | Mean IoU: 0.7941\n",
            ">>>> [Epoch: 162] Training\n",
            ">>>> [Epoch: 162] Avg. loss: 0.1758 | Mean IoU: 0.7914\n",
            ">>>> [Epoch: 163] Training\n",
            ">>>> [Epoch: 163] Avg. loss: 0.1759 | Mean IoU: 0.7932\n",
            ">>>> [Epoch: 164] Training\n",
            ">>>> [Epoch: 164] Avg. loss: 0.1746 | Mean IoU: 0.7919\n",
            ">>>> [Epoch: 165] Training\n",
            ">>>> [Epoch: 165] Avg. loss: 0.1739 | Mean IoU: 0.7925\n",
            ">>>> [Epoch: 166] Training\n",
            ">>>> [Epoch: 166] Avg. loss: 0.1725 | Mean IoU: 0.7933\n",
            ">>>> [Epoch: 167] Training\n",
            ">>>> [Epoch: 167] Avg. loss: 0.1741 | Mean IoU: 0.7939\n",
            ">>>> [Epoch: 168] Training\n",
            ">>>> [Epoch: 168] Avg. loss: 0.1715 | Mean IoU: 0.7939\n",
            ">>>> [Epoch: 169] Training\n",
            ">>>> [Epoch: 169] Avg. loss: 0.1751 | Mean IoU: 0.7945\n",
            ">>>> [Epoch: 169] Validation\n",
            ">>>> [Epoch: 169] Avg. loss: 0.5401 | Mean IoU: 0.6543\n",
            ">>>> [Epoch: 170] Training\n",
            ">>>> [Epoch: 170] Avg. loss: 0.1772 | Mean IoU: 0.7908\n",
            ">>>> [Epoch: 171] Training\n",
            ">>>> [Epoch: 171] Avg. loss: 0.1726 | Mean IoU: 0.7947\n",
            ">>>> [Epoch: 172] Training\n",
            ">>>> [Epoch: 172] Avg. loss: 0.1730 | Mean IoU: 0.7936\n",
            ">>>> [Epoch: 173] Training\n",
            ">>>> [Epoch: 173] Avg. loss: 0.1716 | Mean IoU: 0.7938\n",
            ">>>> [Epoch: 174] Training\n",
            ">>>> [Epoch: 174] Avg. loss: 0.1706 | Mean IoU: 0.7943\n",
            ">>>> [Epoch: 175] Training\n",
            ">>>> [Epoch: 175] Avg. loss: 0.1741 | Mean IoU: 0.7959\n",
            ">>>> [Epoch: 176] Training\n",
            ">>>> [Epoch: 176] Avg. loss: 0.1720 | Mean IoU: 0.7945\n",
            ">>>> [Epoch: 177] Training\n",
            ">>>> [Epoch: 177] Avg. loss: 0.1730 | Mean IoU: 0.7942\n",
            ">>>> [Epoch: 178] Training\n",
            ">>>> [Epoch: 178] Avg. loss: 0.1749 | Mean IoU: 0.7927\n",
            ">>>> [Epoch: 179] Training\n",
            ">>>> [Epoch: 179] Avg. loss: 0.1715 | Mean IoU: 0.7940\n",
            ">>>> [Epoch: 179] Validation\n",
            ">>>> [Epoch: 179] Avg. loss: 0.5398 | Mean IoU: 0.6531\n",
            ">>>> [Epoch: 180] Training\n",
            ">>>> [Epoch: 180] Avg. loss: 0.1701 | Mean IoU: 0.7960\n",
            ">>>> [Epoch: 181] Training\n",
            ">>>> [Epoch: 181] Avg. loss: 0.1695 | Mean IoU: 0.7969\n",
            ">>>> [Epoch: 182] Training\n",
            ">>>> [Epoch: 182] Avg. loss: 0.1731 | Mean IoU: 0.7942\n",
            ">>>> [Epoch: 183] Training\n",
            ">>>> [Epoch: 183] Avg. loss: 0.1722 | Mean IoU: 0.7967\n",
            ">>>> [Epoch: 184] Training\n",
            ">>>> [Epoch: 184] Avg. loss: 0.1719 | Mean IoU: 0.7943\n",
            ">>>> [Epoch: 185] Training\n",
            ">>>> [Epoch: 185] Avg. loss: 0.1729 | Mean IoU: 0.7932\n",
            ">>>> [Epoch: 186] Training\n",
            ">>>> [Epoch: 186] Avg. loss: 0.1716 | Mean IoU: 0.7961\n",
            ">>>> [Epoch: 187] Training\n",
            ">>>> [Epoch: 187] Avg. loss: 0.1709 | Mean IoU: 0.7932\n",
            ">>>> [Epoch: 188] Training\n",
            ">>>> [Epoch: 188] Avg. loss: 0.1690 | Mean IoU: 0.7966\n",
            ">>>> [Epoch: 189] Training\n",
            ">>>> [Epoch: 189] Avg. loss: 0.1716 | Mean IoU: 0.7956\n",
            ">>>> [Epoch: 189] Validation\n",
            ">>>> [Epoch: 189] Avg. loss: 0.5422 | Mean IoU: 0.6569\n",
            "sky: 0.9364\n",
            "building: 0.8454\n",
            "pole: 0.0559\n",
            "road: 0.9656\n",
            "pavement: 0.8552\n",
            "tree: 0.8906\n",
            "sign_symbol: 0.2995\n",
            "fence: 0.6715\n",
            "car: 0.6929\n",
            "pedestrian: 0.3497\n",
            "bicyclist: 0.6631\n",
            "unlabeled: nan\n",
            "\n",
            "Best model thus far. Saving...\n",
            "\n",
            ">>>> [Epoch: 190] Training\n",
            ">>>> [Epoch: 190] Avg. loss: 0.1709 | Mean IoU: 0.7952\n",
            ">>>> [Epoch: 191] Training\n",
            ">>>> [Epoch: 191] Avg. loss: 0.1685 | Mean IoU: 0.7976\n",
            ">>>> [Epoch: 192] Training\n",
            ">>>> [Epoch: 192] Avg. loss: 0.1705 | Mean IoU: 0.7957\n",
            ">>>> [Epoch: 193] Training\n",
            ">>>> [Epoch: 193] Avg. loss: 0.1705 | Mean IoU: 0.7965\n",
            ">>>> [Epoch: 194] Training\n",
            ">>>> [Epoch: 194] Avg. loss: 0.1694 | Mean IoU: 0.7955\n",
            ">>>> [Epoch: 195] Training\n",
            ">>>> [Epoch: 195] Avg. loss: 0.1694 | Mean IoU: 0.7955\n",
            ">>>> [Epoch: 196] Training\n",
            ">>>> [Epoch: 196] Avg. loss: 0.1644 | Mean IoU: 0.8006\n",
            ">>>> [Epoch: 197] Training\n",
            ">>>> [Epoch: 197] Avg. loss: 0.1679 | Mean IoU: 0.7968\n",
            ">>>> [Epoch: 198] Training\n",
            ">>>> [Epoch: 198] Avg. loss: 0.1677 | Mean IoU: 0.7994\n",
            ">>>> [Epoch: 199] Training\n",
            ">>>> [Epoch: 199] Avg. loss: 0.1683 | Mean IoU: 0.7971\n",
            ">>>> [Epoch: 199] Validation\n",
            ">>>> [Epoch: 199] Avg. loss: 0.5639 | Mean IoU: 0.6516\n",
            ">>>> [Epoch: 200] Training\n",
            ">>>> [Epoch: 200] Avg. loss: 0.1654 | Mean IoU: 0.7997\n",
            ">>>> [Epoch: 201] Training\n",
            ">>>> [Epoch: 201] Avg. loss: 0.1667 | Mean IoU: 0.7993\n",
            ">>>> [Epoch: 202] Training\n",
            ">>>> [Epoch: 202] Avg. loss: 0.1676 | Mean IoU: 0.8002\n",
            ">>>> [Epoch: 203] Training\n",
            ">>>> [Epoch: 203] Avg. loss: 0.1664 | Mean IoU: 0.7988\n",
            ">>>> [Epoch: 204] Training\n",
            ">>>> [Epoch: 204] Avg. loss: 0.1656 | Mean IoU: 0.7995\n",
            ">>>> [Epoch: 205] Training\n",
            ">>>> [Epoch: 205] Avg. loss: 0.1652 | Mean IoU: 0.7996\n",
            ">>>> [Epoch: 206] Training\n",
            ">>>> [Epoch: 206] Avg. loss: 0.1679 | Mean IoU: 0.8001\n",
            ">>>> [Epoch: 207] Training\n",
            ">>>> [Epoch: 207] Avg. loss: 0.1649 | Mean IoU: 0.7988\n",
            ">>>> [Epoch: 208] Training\n",
            ">>>> [Epoch: 208] Avg. loss: 0.1647 | Mean IoU: 0.8009\n",
            ">>>> [Epoch: 209] Training\n",
            ">>>> [Epoch: 209] Avg. loss: 0.1683 | Mean IoU: 0.7982\n",
            ">>>> [Epoch: 209] Validation\n",
            ">>>> [Epoch: 209] Avg. loss: 0.5660 | Mean IoU: 0.6544\n",
            ">>>> [Epoch: 210] Training\n",
            ">>>> [Epoch: 210] Avg. loss: 0.1673 | Mean IoU: 0.7967\n",
            ">>>> [Epoch: 211] Training\n",
            ">>>> [Epoch: 211] Avg. loss: 0.1651 | Mean IoU: 0.7990\n",
            ">>>> [Epoch: 212] Training\n",
            ">>>> [Epoch: 212] Avg. loss: 0.1673 | Mean IoU: 0.7988\n",
            ">>>> [Epoch: 213] Training\n",
            ">>>> [Epoch: 213] Avg. loss: 0.1672 | Mean IoU: 0.7994\n",
            ">>>> [Epoch: 214] Training\n",
            ">>>> [Epoch: 214] Avg. loss: 0.1646 | Mean IoU: 0.8007\n",
            ">>>> [Epoch: 215] Training\n",
            ">>>> [Epoch: 215] Avg. loss: 0.1670 | Mean IoU: 0.8009\n",
            ">>>> [Epoch: 216] Training\n",
            ">>>> [Epoch: 216] Avg. loss: 0.1655 | Mean IoU: 0.7995\n",
            ">>>> [Epoch: 217] Training\n",
            ">>>> [Epoch: 217] Avg. loss: 0.1678 | Mean IoU: 0.7997\n",
            ">>>> [Epoch: 218] Training\n",
            ">>>> [Epoch: 218] Avg. loss: 0.1661 | Mean IoU: 0.7989\n",
            ">>>> [Epoch: 219] Training\n",
            ">>>> [Epoch: 219] Avg. loss: 0.1656 | Mean IoU: 0.8003\n",
            ">>>> [Epoch: 219] Validation\n",
            ">>>> [Epoch: 219] Avg. loss: 0.5688 | Mean IoU: 0.6533\n",
            ">>>> [Epoch: 220] Training\n",
            ">>>> [Epoch: 220] Avg. loss: 0.1643 | Mean IoU: 0.8003\n",
            ">>>> [Epoch: 221] Training\n",
            ">>>> [Epoch: 221] Avg. loss: 0.1640 | Mean IoU: 0.8002\n",
            ">>>> [Epoch: 222] Training\n",
            ">>>> [Epoch: 222] Avg. loss: 0.1637 | Mean IoU: 0.8018\n",
            ">>>> [Epoch: 223] Training\n",
            ">>>> [Epoch: 223] Avg. loss: 0.1668 | Mean IoU: 0.7995\n",
            ">>>> [Epoch: 224] Training\n",
            ">>>> [Epoch: 224] Avg. loss: 0.1650 | Mean IoU: 0.8008\n",
            ">>>> [Epoch: 225] Training\n",
            ">>>> [Epoch: 225] Avg. loss: 0.1680 | Mean IoU: 0.7991\n",
            ">>>> [Epoch: 226] Training\n",
            ">>>> [Epoch: 226] Avg. loss: 0.1659 | Mean IoU: 0.8007\n",
            ">>>> [Epoch: 227] Training\n",
            ">>>> [Epoch: 227] Avg. loss: 0.1635 | Mean IoU: 0.8014\n",
            ">>>> [Epoch: 228] Training\n",
            ">>>> [Epoch: 228] Avg. loss: 0.1633 | Mean IoU: 0.8018\n",
            ">>>> [Epoch: 229] Training\n",
            ">>>> [Epoch: 229] Avg. loss: 0.1637 | Mean IoU: 0.8013\n",
            ">>>> [Epoch: 229] Validation\n",
            ">>>> [Epoch: 229] Avg. loss: 0.5660 | Mean IoU: 0.6545\n",
            ">>>> [Epoch: 230] Training\n",
            ">>>> [Epoch: 230] Avg. loss: 0.1648 | Mean IoU: 0.8004\n",
            ">>>> [Epoch: 231] Training\n",
            ">>>> [Epoch: 231] Avg. loss: 0.1672 | Mean IoU: 0.8003\n",
            ">>>> [Epoch: 232] Training\n",
            ">>>> [Epoch: 232] Avg. loss: 0.1674 | Mean IoU: 0.7993\n",
            ">>>> [Epoch: 233] Training\n",
            ">>>> [Epoch: 233] Avg. loss: 0.1654 | Mean IoU: 0.8000\n",
            ">>>> [Epoch: 234] Training\n",
            ">>>> [Epoch: 234] Avg. loss: 0.1658 | Mean IoU: 0.8006\n",
            ">>>> [Epoch: 235] Training\n",
            ">>>> [Epoch: 235] Avg. loss: 0.1655 | Mean IoU: 0.8007\n",
            ">>>> [Epoch: 236] Training\n",
            ">>>> [Epoch: 236] Avg. loss: 0.1662 | Mean IoU: 0.7992\n",
            ">>>> [Epoch: 237] Training\n",
            ">>>> [Epoch: 237] Avg. loss: 0.1619 | Mean IoU: 0.8005\n",
            ">>>> [Epoch: 238] Training\n",
            ">>>> [Epoch: 238] Avg. loss: 0.1665 | Mean IoU: 0.8009\n",
            ">>>> [Epoch: 239] Training\n",
            ">>>> [Epoch: 239] Avg. loss: 0.1657 | Mean IoU: 0.7998\n",
            ">>>> [Epoch: 239] Validation\n",
            ">>>> [Epoch: 239] Avg. loss: 0.5580 | Mean IoU: 0.6550\n",
            ">>>> [Epoch: 240] Training\n",
            ">>>> [Epoch: 240] Avg. loss: 0.1651 | Mean IoU: 0.7992\n",
            ">>>> [Epoch: 241] Training\n",
            ">>>> [Epoch: 241] Avg. loss: 0.1648 | Mean IoU: 0.8010\n",
            ">>>> [Epoch: 242] Training\n",
            ">>>> [Epoch: 242] Avg. loss: 0.1652 | Mean IoU: 0.7999\n",
            ">>>> [Epoch: 243] Training\n",
            ">>>> [Epoch: 243] Avg. loss: 0.1654 | Mean IoU: 0.8006\n",
            ">>>> [Epoch: 244] Training\n",
            ">>>> [Epoch: 244] Avg. loss: 0.1680 | Mean IoU: 0.8014\n",
            ">>>> [Epoch: 245] Training\n",
            ">>>> [Epoch: 245] Avg. loss: 0.1659 | Mean IoU: 0.7986\n",
            ">>>> [Epoch: 246] Training\n",
            ">>>> [Epoch: 246] Avg. loss: 0.1636 | Mean IoU: 0.8010\n",
            ">>>> [Epoch: 247] Training\n",
            ">>>> [Epoch: 247] Avg. loss: 0.1652 | Mean IoU: 0.8004\n",
            ">>>> [Epoch: 248] Training\n",
            ">>>> [Epoch: 248] Avg. loss: 0.1617 | Mean IoU: 0.8026\n",
            ">>>> [Epoch: 249] Training\n",
            ">>>> [Epoch: 249] Avg. loss: 0.1644 | Mean IoU: 0.8020\n",
            ">>>> [Epoch: 249] Validation\n",
            ">>>> [Epoch: 249] Avg. loss: 0.5649 | Mean IoU: 0.6550\n",
            ">>>> [Epoch: 250] Training\n",
            ">>>> [Epoch: 250] Avg. loss: 0.1643 | Mean IoU: 0.8016\n",
            ">>>> [Epoch: 251] Training\n",
            ">>>> [Epoch: 251] Avg. loss: 0.1627 | Mean IoU: 0.8011\n",
            ">>>> [Epoch: 252] Training\n",
            ">>>> [Epoch: 252] Avg. loss: 0.1660 | Mean IoU: 0.8003\n",
            ">>>> [Epoch: 253] Training\n",
            ">>>> [Epoch: 253] Avg. loss: 0.1631 | Mean IoU: 0.8026\n",
            ">>>> [Epoch: 254] Training\n",
            ">>>> [Epoch: 254] Avg. loss: 0.1630 | Mean IoU: 0.8014\n",
            ">>>> [Epoch: 255] Training\n",
            ">>>> [Epoch: 255] Avg. loss: 0.1642 | Mean IoU: 0.8013\n",
            ">>>> [Epoch: 256] Training\n",
            ">>>> [Epoch: 256] Avg. loss: 0.1655 | Mean IoU: 0.7996\n",
            ">>>> [Epoch: 257] Training\n",
            ">>>> [Epoch: 257] Avg. loss: 0.1650 | Mean IoU: 0.8010\n",
            ">>>> [Epoch: 258] Training\n",
            ">>>> [Epoch: 258] Avg. loss: 0.1643 | Mean IoU: 0.8020\n",
            ">>>> [Epoch: 259] Training\n",
            ">>>> [Epoch: 259] Avg. loss: 0.1650 | Mean IoU: 0.8008\n",
            ">>>> [Epoch: 259] Validation\n",
            ">>>> [Epoch: 259] Avg. loss: 0.5625 | Mean IoU: 0.6522\n",
            ">>>> [Epoch: 260] Training\n",
            ">>>> [Epoch: 260] Avg. loss: 0.1658 | Mean IoU: 0.7996\n",
            ">>>> [Epoch: 261] Training\n",
            ">>>> [Epoch: 261] Avg. loss: 0.1649 | Mean IoU: 0.8011\n",
            ">>>> [Epoch: 262] Training\n",
            ">>>> [Epoch: 262] Avg. loss: 0.1640 | Mean IoU: 0.8014\n",
            ">>>> [Epoch: 263] Training\n",
            ">>>> [Epoch: 263] Avg. loss: 0.1641 | Mean IoU: 0.7998\n",
            ">>>> [Epoch: 264] Training\n",
            ">>>> [Epoch: 264] Avg. loss: 0.1638 | Mean IoU: 0.8010\n",
            ">>>> [Epoch: 265] Training\n",
            ">>>> [Epoch: 265] Avg. loss: 0.1658 | Mean IoU: 0.8015\n",
            ">>>> [Epoch: 266] Training\n",
            ">>>> [Epoch: 266] Avg. loss: 0.1632 | Mean IoU: 0.8008\n",
            ">>>> [Epoch: 267] Training\n",
            ">>>> [Epoch: 267] Avg. loss: 0.1675 | Mean IoU: 0.7994\n",
            ">>>> [Epoch: 268] Training\n",
            ">>>> [Epoch: 268] Avg. loss: 0.1630 | Mean IoU: 0.8002\n",
            ">>>> [Epoch: 269] Training\n",
            ">>>> [Epoch: 269] Avg. loss: 0.1625 | Mean IoU: 0.8038\n",
            ">>>> [Epoch: 269] Validation\n",
            ">>>> [Epoch: 269] Avg. loss: 0.5687 | Mean IoU: 0.6558\n",
            ">>>> [Epoch: 270] Training\n",
            ">>>> [Epoch: 270] Avg. loss: 0.1631 | Mean IoU: 0.8011\n",
            ">>>> [Epoch: 271] Training\n",
            ">>>> [Epoch: 271] Avg. loss: 0.1654 | Mean IoU: 0.8012\n",
            ">>>> [Epoch: 272] Training\n",
            ">>>> [Epoch: 272] Avg. loss: 0.1652 | Mean IoU: 0.8022\n",
            ">>>> [Epoch: 273] Training\n",
            ">>>> [Epoch: 273] Avg. loss: 0.1625 | Mean IoU: 0.8020\n",
            ">>>> [Epoch: 274] Training\n",
            ">>>> [Epoch: 274] Avg. loss: 0.1609 | Mean IoU: 0.8022\n",
            ">>>> [Epoch: 275] Training\n",
            ">>>> [Epoch: 275] Avg. loss: 0.1620 | Mean IoU: 0.8025\n",
            ">>>> [Epoch: 276] Training\n",
            ">>>> [Epoch: 276] Avg. loss: 0.1665 | Mean IoU: 0.8005\n",
            ">>>> [Epoch: 277] Training\n",
            ">>>> [Epoch: 277] Avg. loss: 0.1627 | Mean IoU: 0.8008\n",
            ">>>> [Epoch: 278] Training\n",
            ">>>> [Epoch: 278] Avg. loss: 0.1632 | Mean IoU: 0.8022\n",
            ">>>> [Epoch: 279] Training\n",
            ">>>> [Epoch: 279] Avg. loss: 0.1684 | Mean IoU: 0.7993\n",
            ">>>> [Epoch: 279] Validation\n",
            ">>>> [Epoch: 279] Avg. loss: 0.5643 | Mean IoU: 0.6563\n",
            ">>>> [Epoch: 280] Training\n",
            ">>>> [Epoch: 280] Avg. loss: 0.1632 | Mean IoU: 0.7998\n",
            ">>>> [Epoch: 281] Training\n",
            ">>>> [Epoch: 281] Avg. loss: 0.1614 | Mean IoU: 0.8024\n",
            ">>>> [Epoch: 282] Training\n",
            ">>>> [Epoch: 282] Avg. loss: 0.1651 | Mean IoU: 0.7999\n",
            ">>>> [Epoch: 283] Training\n",
            ">>>> [Epoch: 283] Avg. loss: 0.1630 | Mean IoU: 0.8023\n",
            ">>>> [Epoch: 284] Training\n",
            ">>>> [Epoch: 284] Avg. loss: 0.1645 | Mean IoU: 0.8013\n",
            ">>>> [Epoch: 285] Training\n",
            ">>>> [Epoch: 285] Avg. loss: 0.1643 | Mean IoU: 0.8001\n",
            ">>>> [Epoch: 286] Training\n",
            ">>>> [Epoch: 286] Avg. loss: 0.1652 | Mean IoU: 0.8022\n",
            ">>>> [Epoch: 287] Training\n",
            ">>>> [Epoch: 287] Avg. loss: 0.1651 | Mean IoU: 0.8013\n",
            ">>>> [Epoch: 288] Training\n",
            ">>>> [Epoch: 288] Avg. loss: 0.1626 | Mean IoU: 0.8006\n",
            ">>>> [Epoch: 289] Training\n",
            ">>>> [Epoch: 289] Avg. loss: 0.1631 | Mean IoU: 0.8021\n",
            ">>>> [Epoch: 289] Validation\n",
            ">>>> [Epoch: 289] Avg. loss: 0.5613 | Mean IoU: 0.6546\n",
            ">>>> [Epoch: 290] Training\n",
            ">>>> [Epoch: 290] Avg. loss: 0.1636 | Mean IoU: 0.8046\n",
            ">>>> [Epoch: 291] Training\n",
            ">>>> [Epoch: 291] Avg. loss: 0.1636 | Mean IoU: 0.8003\n",
            ">>>> [Epoch: 292] Training\n",
            ">>>> [Epoch: 292] Avg. loss: 0.1634 | Mean IoU: 0.8018\n",
            ">>>> [Epoch: 293] Training\n",
            ">>>> [Epoch: 293] Avg. loss: 0.1626 | Mean IoU: 0.8025\n",
            ">>>> [Epoch: 294] Training\n",
            ">>>> [Epoch: 294] Avg. loss: 0.1636 | Mean IoU: 0.8033\n",
            ">>>> [Epoch: 295] Training\n",
            ">>>> [Epoch: 295] Avg. loss: 0.1628 | Mean IoU: 0.8014\n",
            ">>>> [Epoch: 296] Training\n",
            ">>>> [Epoch: 296] Avg. loss: 0.1617 | Mean IoU: 0.8017\n",
            ">>>> [Epoch: 297] Training\n",
            ">>>> [Epoch: 297] Avg. loss: 0.1650 | Mean IoU: 0.8003\n",
            ">>>> [Epoch: 298] Training\n",
            ">>>> [Epoch: 298] Avg. loss: 0.1633 | Mean IoU: 0.8015\n",
            ">>>> [Epoch: 299] Training\n",
            ">>>> [Epoch: 299] Avg. loss: 0.1670 | Mean IoU: 0.7990\n",
            ">>>> [Epoch: 299] Validation\n",
            ">>>> [Epoch: 299] Avg. loss: 0.5638 | Mean IoU: 0.6554\n",
            "sky: 0.9351\n",
            "building: 0.8489\n",
            "pole: 0.0548\n",
            "road: 0.9655\n",
            "pavement: 0.8549\n",
            "tree: 0.8911\n",
            "sign_symbol: 0.3086\n",
            "fence: 0.6704\n",
            "car: 0.6922\n",
            "pedestrian: 0.3418\n",
            "bicyclist: 0.6455\n",
            "unlabeled: nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ll"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fy_CB1hqhQhS",
        "outputId": "50894624-b100-466f-b0df-30560641464a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 4\n",
            "drwxr-xr-x 1 root 4096 Jun  1 13:50 \u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbVqI1d8hQks",
        "outputId": "e5f4cc29-f65b-49cb-d186-f374fe659c05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mbin\u001b[0m/      \u001b[01;34mdev\u001b[0m/   \u001b[01;34mlib32\u001b[0m/  \u001b[01;34mopt\u001b[0m/         \u001b[01;34mrun\u001b[0m/   \u001b[01;34mtensorflow-1.15.2\u001b[0m/  \u001b[01;34mvar\u001b[0m/\n",
            "\u001b[01;34mboot\u001b[0m/     \u001b[01;34metc\u001b[0m/   \u001b[01;34mlib64\u001b[0m/  \u001b[01;34mproc\u001b[0m/        \u001b[01;34msbin\u001b[0m/  \u001b[30;42mtmp\u001b[0m/\n",
            "\u001b[01;34mcontent\u001b[0m/  \u001b[01;34mhome\u001b[0m/  \u001b[01;34mmedia\u001b[0m/  \u001b[01;34mpython-apt\u001b[0m/  \u001b[01;34msrv\u001b[0m/   \u001b[01;34mtools\u001b[0m/\n",
            "\u001b[01;34mdatalab\u001b[0m/  \u001b[01;34mlib\u001b[0m/   \u001b[01;34mmnt\u001b[0m/    \u001b[01;34mroot\u001b[0m/        \u001b[01;34msys\u001b[0m/   \u001b[01;34musr\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KWs1YsChvLn",
        "outputId": "01475f03-c489-4f09-a5c5-db3893136784"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 新段落"
      ],
      "metadata": {
        "id": "BkC_8W2Xgi2D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5mt8ep1fhz0d",
        "outputId": "954b49a9-640f-4269-9e2c-c6d8b21f6f5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd sample_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07ZCfexsh09G",
        "outputId": "260d2804-ae2d-48e4-a980-8c8ec862e0cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_5g4X5ih3mP",
        "outputId": "8262ff0d-8ce1-4065-8e27-9d9e3995b8cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;32manscombe.json\u001b[0m*                mnist_test.csv\n",
            "california_housing_test.csv   mnist_train_small.csv\n",
            "california_housing_train.csv  \u001b[01;32mREADME.md\u001b[0m*\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py -m test.py --save-dir save/folder/ --name model_name --dataset-dir pa"
      ],
      "metadata": {
        "id": "mYy_m8Lah41I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}